{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Box2D: `pip install \"gymnasium[box2d]\"`\n",
    "To play with the car racing game: `python env/lib/python3.9/site-packages/gymnasium/envs/box2d/car_racing.py`\n",
    "\n",
    "In continuous space, there are 3 actions:\n",
    "* 0: steering, -1 is full left, +1 is full right\n",
    "* 1: gas\n",
    "* 2: breaking\n",
    "\n",
    "In discrete space there are 5 actions:\n",
    "* 0: do nothing\n",
    "* 1: steer left\n",
    "* 2: steer right\n",
    "* 3: gas\n",
    "* 4: brake\n",
    "\n",
    "Observation space: a top-down 96x96 RGB image of the car and race track.\n",
    "\n",
    "The reward is -0.1 every frame and +1000/N for every track tile visited, where N is the total number of tiles visited in the track. For example, if you have finished in 732 frames, your reward is 1000 - 0.1*732 = 926.8 points.\n",
    "\n",
    "The episode finishes when all the tiles are visited. The car can also go outside the playfield - that is, far off the track, in which case it will receive -100 reward and die."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "transforms = T.Compose([\n",
    "    T.ToTensor(),  # scale to [0, 1] adds batch dim\n",
    "    # crop removes the black footer and crops the image to 84x84\n",
    "    T.Lambda(lambda img: T.functional.crop(img, top=0, left=6, height=84, width=84)),\n",
    "    T.Grayscale(),\n",
    "    # T.Resize(size=(16,16), antialias=False),\n",
    "])\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        frame_stack_len = 3  # number of contiguous frames ingested\n",
    "\n",
    "        # (steering, gas, break)\n",
    "        # limiting the action space seems to greatly improve training.\n",
    "        # policy doesn't even learn to turn otherwise.\n",
    "        self.action_space = np.array([\n",
    "            [-1, 1, 0], [0, 1, 0], [1, 1, 0],\n",
    "            [-1, 0.5, 0], [0, 0.5, 0], [1, 0.5, 0],\n",
    "            [-1, 0, 0.2], [0, 0, 0.2], [1, 0, 0.2],\n",
    "            [-1, 0, 0], [0, 0, 0], [1, 0, 0]\n",
    "        ])\n",
    "\n",
    "        self.n_actions = len(self.action_space)\n",
    "\n",
    "        # self.steering_bins = np.linspace(-1, 1, 21)\n",
    "        # self.gaz_bins = np.linspace(0, 1, 11)\n",
    "        # self.brake_bins = np.linspace(0, 1, 11)\n",
    "        # n_actions = len(self.steering_bins) + len(self.gaz_bins) + len(self.brake_bins)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(frame_stack_len, 6, (7, 7), stride=3)\n",
    "        self.conv2 = nn.Conv2d(6, 12, (4, 4), stride=1)\n",
    "        self.lin1 = nn.Linear(300, 128)\n",
    "        self.lin2 = nn.Linear(128, self.n_actions)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.max_pool2d(out, kernel_size=(2, 2))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, kernel_size=(2, 2))\n",
    "        out = out.reshape(batch_size, -1)\n",
    "        out = F.relu(self.lin1(out))\n",
    "        out = self.lin2(out)\n",
    "        return out  # batch_size, n_actions\n",
    "\n",
    "    def act(self, epsilon, state):\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            return random.randint(0, self.n_actions-1)\n",
    "\n",
    "        with torch.no_grad(): \n",
    "            q = self.forward(state)\n",
    "            a = int(q.argmax(-1)[0])  # select first element to eliminate batch dim\n",
    "            return a\n",
    "    \n",
    "    # def get_action(self, idx):\n",
    "    #     if idx < len(self.steering_bins):\n",
    "    #         return np.array([self.steering_bins[idx], 0, 0])\n",
    "    #     elif idx < len(self.steering_bins) + len(self.gaz_bins):\n",
    "    #         return np.array([0, self.gaz_bins[idx - len(self.steering_bins)], 0])\n",
    "    #     else:\n",
    "    #         return np.array([0, self.brake_bins[idx - len(self.steering_bins) - len(self.gaz_bins)], 0])\n",
    "        \n",
    "    def compute_loss(self, s, y, a):\n",
    "        out = self.forward(s)\n",
    "        q = out[np.arange(out.shape[0]), a]\n",
    "        return F.mse_loss(q, y, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00778508186340332,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b5e4f7fe274401b027c8ab55f775ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014368295669555664,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 200000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c8c3c622db403cafa44162dd5f9fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import pickle\n",
    "from collections import deque\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import gymnasium as gym\n",
    "# domain_randomize: background and track colours are different on every reset.\n",
    "env = gym.make(\"CarRacing-v2\", domain_randomize=False, continuous=True)\n",
    "\n",
    "# state size = 16*16 img *4 frames = 1024 bytes\n",
    "# 100 MB buffer size = 100 000 states\n",
    "# buffer has to be large enough to break correlations between multiple states\n",
    "buffer_size = 5000\n",
    "buffer = deque(maxlen=buffer_size)  # will automatically pop items when we go over the buffer_size#\n",
    "buffer_pbar = tqdm(total=buffer_size)  # progress bar to keep track of buffer filling up.\n",
    "\n",
    "frame_stack_len = 3\n",
    "skip_frames = 2\n",
    "epsilon = 1\n",
    "epsilon_min = 0.1\n",
    "epsilon_decay = np.exp(np.log(epsilon_min/epsilon)/60000)  # such that epsilon * epsilon_decay ** 60k steps = epsilon_min\n",
    "\n",
    "batch_size = 64\n",
    "gamma = 0.95\n",
    "\n",
    "model = DQN()\n",
    "target_model = DQN()\n",
    "\n",
    "def sync_models(model, target_model, path=\"./checkpoints/model_sync.pt\"):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    target_model.load_state_dict(torch.load(path))\n",
    "\n",
    "sync_models(model, target_model)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-3)\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# n_episodes = 100\n",
    "n_updates = 200000\n",
    "pbar = tqdm(total=n_updates)\n",
    "updates_counter = 0\n",
    "episode_counter = 0\n",
    "best_total_reward = 0\n",
    "sync_models_frequency = 5  # episodes\n",
    "while updates_counter < n_updates:\n",
    "    episode_counter += 1\n",
    "    # normal reset changes the colour scheme by default\n",
    "    obs, info = env.reset()\n",
    "    s = transforms(obs)\n",
    "    frame_stack = deque(maxlen=frame_stack_len)\n",
    "    frame_stack.extend([s for _ in range(frame_stack_len)])  # init with the same state.\n",
    "    done = False\n",
    "    t = 1\n",
    "    total_loss = 0\n",
    "    total_reward = 0\n",
    "    off_track_counter = 0\n",
    "    gas_counter = 0  # how many steps was gas > 0\n",
    "    negative_reward_counter = 0\n",
    "    while not done:\n",
    "        state = torch.concatenate(list(frame_stack), dim=0)\n",
    "        state = state.unsqueeze(0)  # add batch dim\n",
    "        a = model.act(epsilon, state)\n",
    "        a_arr = model.action_space[a]\n",
    "        reward = 0\n",
    "        off_track = False\n",
    "        off_map = False\n",
    "        # repeat same action over skip_frames\n",
    "        for _ in range(skip_frames):\n",
    "            t += 1\n",
    "            new_obs, r, terminated, truncated, info = env.step(a_arr)\n",
    "            off_track = off_track or np.isclose(reward, -0.1)  # hacky way to check if race car is off track...\n",
    "            off_track_counter += 1 if off_track else 0\n",
    "            off_map = np.isclose(reward, -100)\n",
    "            if off_track or off_map:\n",
    "                r = -1\n",
    "            gas = a_arr[1] > 0\n",
    "            gas_counter += 1 if gas else 0\n",
    "            if gas: # gas\n",
    "                r *= 1.5\n",
    "            reward += r\n",
    "            done = terminated or truncated\n",
    "            if done:\n",
    "                break\n",
    "            \n",
    "        new_s = transforms(new_obs)\n",
    "        frame_stack.append(new_s)\n",
    "\n",
    "        new_state = torch.concatenate(list(frame_stack), dim=0)\n",
    "        new_state = new_state.unsqueeze(0)\n",
    "\n",
    "        # if reward < 0:\n",
    "        #     negative_reward_counter += 1 \n",
    "\n",
    "        total_reward += reward\n",
    "        \n",
    "        buffer.append((state, a, reward, new_state, done))\n",
    "        if len(buffer) < buffer_size:\n",
    "            # only start training once buffer is full\n",
    "            buffer_pbar.update(1)\n",
    "            continue\n",
    "\n",
    "        # construct batch.\n",
    "        batch = {\"r\": [], \"done\": [], \"s\": [], \"new_s\": [], \"a\": []}\n",
    "        for (sj, aj, rj, new_sj, donej) in random.sample(buffer, batch_size):\n",
    "            batch[\"done\"].append(float(donej))\n",
    "            batch[\"r\"].append(rj)\n",
    "            batch[\"s\"].append(sj)\n",
    "            batch[\"new_s\"].append(new_sj)\n",
    "            batch[\"a\"].append(aj)\n",
    "\n",
    "        batch[\"done\"] = torch.tensor(batch[\"done\"])\n",
    "        batch[\"r\"] = torch.tensor(batch[\"r\"])\n",
    "        batch[\"s\"] = torch.concatenate(batch[\"s\"], dim=0)\n",
    "        batch[\"new_s\"] = torch.concatenate(batch[\"new_s\"], dim=0)\n",
    "        batch[\"a\"] = torch.tensor(batch[\"a\"], dtype=torch.int)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            q = target_model.forward(batch[\"new_s\"]).max(dim=-1).values\n",
    "            batch[\"y\"] = batch[\"r\"] + (1 - batch[\"done\"]) * gamma * q\n",
    "\n",
    "        loss = model.compute_loss(batch[\"s\"], batch[\"y\"], batch[\"a\"])\n",
    "        total_loss += loss.item()\n",
    "        total_reward += reward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        updates_counter += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "        writer.add_scalar(\"Epsilon\", epsilon, updates_counter)\n",
    "        writer.add_scalar('Loss', loss.item(), updates_counter)\n",
    "        epsilon = max(epsilon * epsilon_decay, epsilon_min)\n",
    "\n",
    "        # early termination of negative episodes. \n",
    "        # This really helped training for some reason. \n",
    "        # Probably because the agent can play more episodes this way.\n",
    "        if done or off_track_counter >= 10 or total_reward < 0:\n",
    "            break\n",
    "\n",
    "    if updates_counter == 0:\n",
    "        continue\n",
    "\n",
    "    writer.add_scalar('Total Reward per episode', total_reward, episode_counter)\n",
    "    writer.add_scalar('Episode length', t, episode_counter)\n",
    "    writer.add_scalar(\"Off track freq\", off_track_counter/t, episode_counter)\n",
    "    writer.add_scalar(\"Gas freq\", gas_counter/t, episode_counter)\n",
    "\n",
    "    if total_reward > best_total_reward:\n",
    "        best_total_reward = total_reward\n",
    "        torch.save(model.state_dict(), \"./checkpoints/best_model.pt\")\n",
    "\n",
    "    if episode_counter % sync_models_frequency == 0:\n",
    "        sync_models(model, target_model)\n",
    "    \n",
    "    if episode_counter % 100 == 0:\n",
    "        torch.save(model.state_dict(), f\"./checkpoints/{episode_counter}.pt\")\n",
    "\n",
    "writer.close()\n",
    "env.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03791689872741699,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 600,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e12f97a6c4f44f7aaa03380c0f04197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saving to GIF...\n",
      "🚀 Done!\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "\n",
    "model.load_state_dict(torch.load(\"./checkpoints/600.pt\"))\n",
    "\n",
    "def sample_episode():\n",
    "    env = gym.make(\"CarRacing-v2\", domain_randomize=False, continuous=True, render_mode=\"rgb_array\")\n",
    "    frames = []\n",
    "    done = False\n",
    "    obs, info = env.reset()\n",
    "    max_frames = 600\n",
    "    counter = 1\n",
    "    frame_stack_len = 3\n",
    "    s = transforms(obs)\n",
    "    frame_stack = deque(maxlen=frame_stack_len)\n",
    "    frame_stack.extend([s for _ in range(frame_stack_len)])\n",
    "    pbar = tqdm(total=max_frames)\n",
    "    while not done and counter <= max_frames:\n",
    "        frame = env.render()\n",
    "        frames.append(frame)\n",
    "        state = torch.concatenate(list(frame_stack), dim=0)\n",
    "        state = state.unsqueeze(0)\n",
    "        a = model.act(epsilon=0, state=state)\n",
    "        action = model.action_space[a]\n",
    "        new_obs, reward, terminated, truncated, info = env.step(action)\n",
    "        frame_stack.append(transforms(new_obs))\n",
    "        done = terminated or truncated\n",
    "        counter += 1\n",
    "        pbar.update(1)\n",
    "    env.close()\n",
    "\n",
    "    print(\"💾 Saving to GIF...\")\n",
    "    fps = 60\n",
    "    imageio.mimsave('carracing.gif', frames, duration=len(frames)/fps)\n",
    "    print(\"🚀 Done!\")\n",
    "    return\n",
    "    \n",
    "\n",
    "sample_episode()                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
